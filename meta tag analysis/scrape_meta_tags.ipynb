{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(r'C:\\Users\\ewais\\Documents\\GitHub\\misinfo_detection\\content_analysis\\analyses v2\\html_df_tokenized.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "274it [06:46, 17.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError at index 50 description\n",
      "continuing...\n",
      "KeyError at index 50 keywords\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "323it [26:23, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError at index 5 keywords\n",
      "continuing...\n",
      "KeyError at index 7 keywords\n",
      "continuing...\n",
      "KeyError at index 8 keywords\n",
      "continuing...\n",
      "KeyError at index 9 keywords\n",
      "continuing...\n",
      "KeyError at index 10 keywords\n",
      "continuing...\n",
      "KeyError at index 11 keywords\n",
      "continuing...\n",
      "KeyError at index 12 keywords\n",
      "continuing...\n",
      "KeyError at index 14 keywords\n",
      "continuing...\n",
      "KeyError at index 15 keywords\n",
      "continuing...\n",
      "KeyError at index 16 keywords\n",
      "continuing...\n",
      "KeyError at index 17 keywords\n",
      "continuing...\n",
      "KeyError at index 18 keywords\n",
      "continuing...\n",
      "KeyError at index 19 keywords\n",
      "continuing...\n",
      "KeyError at index 20 keywords\n",
      "continuing...\n",
      "KeyError at index 21 keywords\n",
      "continuing...\n",
      "KeyError at index 23 twitter:description\n",
      "continuing...\n",
      "KeyError at index 23 description\n",
      "continuing...\n",
      "KeyError at index 86 keywords\n",
      "continuing...\n",
      "KeyError at index 170 keywords\n",
      "continuing...\n",
      "KeyError at index 193 keywords\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [27:07, 26.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError at index 212 keywords\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [1:21:07, 15.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError at index 4 og:description\n",
      "continuing...\n",
      "KeyError at index 80 og:description\n",
      "continuing...\n",
      "KeyError at index 122 og:description\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [1:24:46, 10.17s/it]\n",
      "148it [52:10, 172.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError at index 12 description\n",
      "continuing...\n",
      "KeyError at index 12 keywords\n",
      "continuing...\n",
      "KeyError at index 16 description\n",
      "continuing...\n",
      "KeyError at index 16 keywords\n",
      "continuing...\n",
      "KeyError at index 17 description\n",
      "continuing...\n",
      "KeyError at index 17 keywords\n",
      "continuing...\n",
      "KeyError at index 18 description\n",
      "continuing...\n",
      "KeyError at index 18 keywords\n",
      "continuing...\n",
      "KeyError at index 23 description\n",
      "continuing...\n",
      "KeyError at index 23 keywords\n",
      "continuing...\n",
      "KeyError at index 24 description\n",
      "continuing...\n",
      "KeyError at index 24 keywords\n",
      "continuing...\n",
      "KeyError at index 25 keywords\n",
      "continuing...\n",
      "KeyError at index 39 description\n",
      "continuing...\n",
      "KeyError at index 39 keywords\n",
      "continuing...\n",
      "KeyError at index 41 keywords\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [1:11:53, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError at index 334 keywords\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [1:32:15, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError at index 1 description\n",
      "continuing...\n",
      "KeyError at index 15 description\n",
      "continuing...\n",
      "KeyError at index 68 description\n",
      "continuing...\n",
      "KeyError at index 90 description\n",
      "continuing...\n",
      "KeyError at index 167 description\n",
      "continuing...\n",
      "KeyError at index 167 keywords\n",
      "continuing...\n",
      "KeyError at index 168 description\n",
      "continuing...\n",
      "KeyError at index 183 description\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "443it [2:15:22, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError at index 122 description\n",
      "continuing...\n",
      "KeyError at index 122 keywords\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "499it [2:46:30, 20.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def create_dir(target_directory):\n",
    "    '''Creates directory target_directory if the directory doesn't already exist'''\n",
    "    if not os.path.isdir(str(target_directory)):\n",
    "        os.mkdir(target_directory)\n",
    "\n",
    "def populate_meta_tags(source_dir, target_dir, REAL = True):\n",
    "    '''\n",
    "    Populates target dir with .txt files of scraped meta tags from source dir\n",
    "    Each .txt file contains all visible text\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ARGUMENTS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "    - source_dir\n",
    "        - source of HTML files, should be raw_sources/<real or fake>/html\n",
    "    - target_dir\n",
    "        - directory to save parsed files\n",
    "    '''\n",
    "    for idx, dir_ in tqdm(enumerate([source_dir + '\\\\' + s for s in os.listdir(source_dir)])):\n",
    "        if REAL and (idx < 258):\n",
    "            continue\n",
    "        files = [dir_ + '\\\\' + s for s in os.listdir(dir_)]\n",
    "        dest_dir = target_dir + '\\\\' + dir_.split('\\\\')[-1]\n",
    "        create_dir(dest_dir)\n",
    "        for index, html in enumerate(files):\n",
    "            # Open HTML\n",
    "            with open(html, encoding='utf8') as f:\n",
    "                soup = BeautifulSoup(f, 'html.parser')\n",
    "            f.close()\n",
    "            \n",
    "            # ---------------------------------------------------------------------------- #\n",
    "            #                             open graph meta tags                             #\n",
    "            # ---------------------------------------------------------------------------- #\n",
    "            \n",
    "            # og:title\n",
    "            title = soup.find(\"meta\", property=\"og:title\")\n",
    "            try:\n",
    "                og_title = title['content'] if title else ''\n",
    "            except KeyError:\n",
    "                og_title = ''\n",
    "                print('KeyError at index {} title'.format(index))\n",
    "                print('continuing...')\n",
    "            \n",
    "            # og:keywords\n",
    "            og_keywords = soup.find('meta', property='og:keywords')\n",
    "            try:\n",
    "                og_keywords = og_keywords['content'] if og_keywords else ''\n",
    "            except KeyError:\n",
    "                og_keywords = ''\n",
    "                print('KeyError at index {} og:keywords'.format(index))\n",
    "                print('continuing...')\n",
    "            \n",
    "            # og:description\n",
    "            og_description = soup.find('meta', property='og:description')\n",
    "            try:\n",
    "                og_description = og_description['content'] if og_description else ''\n",
    "            except KeyError:\n",
    "                og_description = ''\n",
    "                print('KeyError at index {} og:description'.format(index))\n",
    "                print('continuing...')\n",
    "\n",
    "\n",
    "            # ---------------------------------------------------------------------------- #\n",
    "            #                               twitter meta tags                              #\n",
    "            # ---------------------------------------------------------------------------- #\n",
    "            \n",
    "            # twitter:title\n",
    "            tw_title = soup.find(\"meta\", attrs={'name':\"twitter:title\"})\n",
    "            try:\n",
    "                tw_title = tw_title['content'] if tw_title else ''\n",
    "            except KeyError:\n",
    "                tw_title = ''\n",
    "                print('KeyError at index {} twitter:title'.format(index))\n",
    "                print('continuing...')\n",
    "            \n",
    "            # twitter:keywords\n",
    "            tw_keywords = soup.find('meta', attrs={'name':\"twitter:keywords\"})\n",
    "            try:\n",
    "                tw_keywords = tw_keywords['content'] if tw_keywords else ''\n",
    "            except KeyError:\n",
    "                tw_keywords = ''\n",
    "                print('KeyError at index {} twitter:keywords'.format(index))\n",
    "                print('continuing...')\n",
    "            \n",
    "            # twitter:description\n",
    "            tw_description = soup.find('meta', attrs={'name':\"twitter:description\"})\n",
    "            try:\n",
    "                tw_description = tw_description['content'] if tw_description else ''\n",
    "            except KeyError:\n",
    "                tw_description = ''\n",
    "                print('KeyError at index {} twitter:description'.format(index))\n",
    "                print('continuing...')\n",
    "\n",
    "            # ---------------------------------------------------------------------------- #\n",
    "            #                               regular meta tags                              #\n",
    "            # ---------------------------------------------------------------------------- #\n",
    "\n",
    "            # keywords, description\n",
    "            description = soup.find('meta', attrs={'name':\"description\"})\n",
    "            try:\n",
    "                description = description['content'] if description else ''\n",
    "            except KeyError:\n",
    "                description = ''\n",
    "                print('KeyError at index {} description'.format(index))\n",
    "                print('continuing...')\n",
    "            \n",
    "            keywords = soup.find('meta', attrs={'name':\"keywords\"})\n",
    "            try:\n",
    "                keywords = keywords['content'] if keywords else ''\n",
    "            except KeyError:\n",
    "                keywords = ''\n",
    "                print('KeyError at index {} keywords'.format(index))\n",
    "                print('continuing...')\n",
    "\n",
    "\n",
    "            # print(f'\\nkeywords {keywords}')\n",
    "            # print(f'description {description}')\n",
    "            # print(f'og_title {og_title}')\n",
    "            # print(f'og_description {og_description}')\n",
    "            # print(f'og_keywords {og_keywords}')\n",
    "            # print(f'tw_description {tw_description}')\n",
    "            # print(f'tw_title {tw_title}')\n",
    "            # print(f'tw_keywords {tw_keywords}')\n",
    "\n",
    "            text = [keywords, description, og_title, og_description, og_keywords, tw_description, tw_title, tw_keywords]\n",
    "\n",
    "            file_name = html.split('\\\\')[-1].split('.')[0] + '.txt'\n",
    "            file_path = dest_dir + '\\\\' + file_name\n",
    "            if any(x != '' for x in text):\n",
    "                with open(file_path, 'a', encoding='utf8') as f:\n",
    "                    f.writelines(text)\n",
    "                f.close()\n",
    "    return\n",
    "\n",
    "real_source_dir = str(Path.cwd().parent / 'content_analysis' / 'raw_sources' / 'real_html' / 'sources')\n",
    "real_target_dir = str(Path.cwd() / 'meta_tags_parsed' / 'real')\n",
    "fake_source_dir = str(Path.cwd().parent / 'content_analysis' / 'raw_sources' / 'fake_html' / 'sources')\n",
    "fake_target_dir = str(Path.cwd() / 'meta_tags_parsed' / 'fake')\n",
    "\n",
    "populate_meta_tags(real_source_dir, real_target_dir, REAL=True)\n",
    "populate_meta_tags(fake_source_dir, fake_target_dir, REAL=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "real_target_dir = str(Path.cwd() / 'meta_tags_parsed' / 'real')\n",
    "\n",
    "print(len(os.listdir(real_target_dir)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
