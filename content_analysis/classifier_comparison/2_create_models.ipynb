{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_index</th>\n",
       "      <th>subindex</th>\n",
       "      <th>site</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>meta text</th>\n",
       "      <th>meta tokenized</th>\n",
       "      <th>domain</th>\n",
       "      <th>...</th>\n",
       "      <th>num_outgoing_real_sites</th>\n",
       "      <th>num_outgoing_sites</th>\n",
       "      <th>outgoing_fake_sites_list</th>\n",
       "      <th>outgoing_real_sites_list</th>\n",
       "      <th>outgoing_sites_list</th>\n",
       "      <th>percent_fake_incoming</th>\n",
       "      <th>percent_fake_outgoing</th>\n",
       "      <th>incoming_to_outgoing_ratio</th>\n",
       "      <th>color</th>\n",
       "      <th>vectorized_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://9to5mac.com</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>In a memo that was leaked to the Verge , Cook ...</td>\n",
       "      <td>[memo, wa, leak, verg, cook, say, appl, “, eve...</td>\n",
       "      <td>News and reviews for Apple products, apps, an...</td>\n",
       "      <td>[news, review, appl, product, app, rumor, prov...</td>\n",
       "      <td>.9to5mac.com</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.deadline.com, .theverge.com, .sfexaminer.com...</td>\n",
       "      <td>[.deadline.com, .theverge.com, .sfexaminer.com...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>blue</td>\n",
       "      <td>[0.8, 0.0, 0.5555555555555556]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://wfae.org</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>Charlotte Talks    Local News Roundup: Housing...</td>\n",
       "      <td>[charlott, talk, local, news, roundup, hous, f...</td>\n",
       "      <td>Charlotte Podcasts,Charlotte music,Charlotte ...</td>\n",
       "      <td>[charlott, podcast, charlott, music, charlott,...</td>\n",
       "      <td>.wfae.org</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.gao.gov, .npr.org, .nytimes.com, .seattletim...</td>\n",
       "      <td>[.gao.gov, .npr.org, .nytimes.com, .seattletim...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>blue</td>\n",
       "      <td>[0.25, 0.0, 0.6666666666666666]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>http://climatefeedback.org</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>The workshop will then move to more concrete e...</td>\n",
       "      <td>[workshop, move, concret, exampl, initi, tackl...</td>\n",
       "      <td>Scientific Reference to Reliable Information ...</td>\n",
       "      <td>[scientif, refer, reliabl, inform, climat, cha...</td>\n",
       "      <td>.climatefeedback.org</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.smithsonianmag.com, .politico.com, .accuweat...</td>\n",
       "      <td>[.smithsonianmag.com, .politico.com, .accuweat...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>blue</td>\n",
       "      <td>[0.0, 0.0, 0.125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>http://wdbj7.com</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>Power Life by Tony Horton            All Adult...</td>\n",
       "      <td>[power, life, toni, horton, adult, due, larg, ...</td>\n",
       "      <td>wdbj, virginia local news, virginia weather, ...</td>\n",
       "      <td>[wdbj, virginia, local, news, virginia, weathe...</td>\n",
       "      <td>.wdbj7.com</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.nasa.gov, .nbc12.com]</td>\n",
       "      <td>[.nasa.gov, .nbc12.com]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>blue</td>\n",
       "      <td>[0.25, 0.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>http://keyc.com</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>Good To Know This       Recommended by        ...</td>\n",
       "      <td>[good, know, thi, recommend, recommend, high, ...</td>\n",
       "      <td>keyc, keyc 12 keyc news 12, keyc tv, keyc new...</td>\n",
       "      <td>[keyc, keyc, keyc, news, keyc, tv, keyc, news,...</td>\n",
       "      <td>.keyc.com</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.startribune.com, .wrtv.com]</td>\n",
       "      <td>[.startribune.com, .wrtv.com]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>blue</td>\n",
       "      <td>[1.0, 0.0, 0.5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_index  subindex                        site label  y  \\\n",
       "0             0         0          http://9to5mac.com  real  0   \n",
       "1             1         1             http://wfae.org  real  0   \n",
       "2             2         2  http://climatefeedback.org  real  0   \n",
       "3             3         3            http://wdbj7.com  real  0   \n",
       "4             4         4             http://keyc.com  real  0   \n",
       "\n",
       "                                                text  \\\n",
       "0  In a memo that was leaked to the Verge , Cook ...   \n",
       "1  Charlotte Talks    Local News Roundup: Housing...   \n",
       "2  The workshop will then move to more concrete e...   \n",
       "3  Power Life by Tony Horton            All Adult...   \n",
       "4  Good To Know This       Recommended by        ...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [memo, wa, leak, verg, cook, say, appl, “, eve...   \n",
       "1  [charlott, talk, local, news, roundup, hous, f...   \n",
       "2  [workshop, move, concret, exampl, initi, tackl...   \n",
       "3  [power, life, toni, horton, adult, due, larg, ...   \n",
       "4  [good, know, thi, recommend, recommend, high, ...   \n",
       "\n",
       "                                           meta text  \\\n",
       "0   News and reviews for Apple products, apps, an...   \n",
       "1   Charlotte Podcasts,Charlotte music,Charlotte ...   \n",
       "2   Scientific Reference to Reliable Information ...   \n",
       "3   wdbj, virginia local news, virginia weather, ...   \n",
       "4   keyc, keyc 12 keyc news 12, keyc tv, keyc new...   \n",
       "\n",
       "                                      meta tokenized                domain  \\\n",
       "0  [news, review, appl, product, app, rumor, prov...          .9to5mac.com   \n",
       "1  [charlott, podcast, charlott, music, charlott,...             .wfae.org   \n",
       "2  [scientif, refer, reliabl, inform, climat, cha...  .climatefeedback.org   \n",
       "3  [wdbj, virginia, local, news, virginia, weathe...            .wdbj7.com   \n",
       "4  [keyc, keyc, keyc, news, keyc, tv, keyc, news,...             .keyc.com   \n",
       "\n",
       "   ...  num_outgoing_real_sites num_outgoing_sites  outgoing_fake_sites_list  \\\n",
       "0  ...                        9                  9                        []   \n",
       "1  ...                        6                  6                        []   \n",
       "2  ...                        8                  8                        []   \n",
       "3  ...                        2                  2                        []   \n",
       "4  ...                        2                  2                        []   \n",
       "\n",
       "                            outgoing_real_sites_list  \\\n",
       "0  [.deadline.com, .theverge.com, .sfexaminer.com...   \n",
       "1  [.gao.gov, .npr.org, .nytimes.com, .seattletim...   \n",
       "2  [.smithsonianmag.com, .politico.com, .accuweat...   \n",
       "3                            [.nasa.gov, .nbc12.com]   \n",
       "4                      [.startribune.com, .wrtv.com]   \n",
       "\n",
       "                                 outgoing_sites_list percent_fake_incoming  \\\n",
       "0  [.deadline.com, .theverge.com, .sfexaminer.com...                  0.80   \n",
       "1  [.gao.gov, .npr.org, .nytimes.com, .seattletim...                  0.25   \n",
       "2  [.smithsonianmag.com, .politico.com, .accuweat...                  0.00   \n",
       "3                            [.nasa.gov, .nbc12.com]                  0.25   \n",
       "4                      [.startribune.com, .wrtv.com]                  1.00   \n",
       "\n",
       "   percent_fake_outgoing  incoming_to_outgoing_ratio  color  \\\n",
       "0                    0.0                    0.555556   blue   \n",
       "1                    0.0                    0.666667   blue   \n",
       "2                    0.0                    0.125000   blue   \n",
       "3                    0.0                    2.000000   blue   \n",
       "4                    0.0                    0.500000   blue   \n",
       "\n",
       "                  vectorized_links  \n",
       "0   [0.8, 0.0, 0.5555555555555556]  \n",
       "1  [0.25, 0.0, 0.6666666666666666]  \n",
       "2                [0.0, 0.0, 0.125]  \n",
       "3                 [0.25, 0.0, 2.0]  \n",
       "4                  [1.0, 0.0, 0.5]  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from analysis_functions import *\n",
    "import pickle\n",
    "\n",
    "# Load the dataframe\n",
    "with open('full_df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 152.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Train and save 100 hyperlinking models\n",
    "def train_hyperlinking_models(num_models, df, out_dir):\n",
    "    '''\n",
    "    To create X, y\n",
    "    y = df['y'].to_numpy()\n",
    "    X = df['vectorized_links'].to_numpy()\n",
    "    '''\n",
    "    for i in tqdm(range(num_models)):\n",
    "        model, _, _, _, _ = train_hyperlinking_SVM(df)\n",
    "        outfile = out_dir / (str(i)+'.pkl')\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        f.close()\n",
    "    return\n",
    "\n",
    "out_dir = Path(r'C:\\Users\\ewais\\Documents\\GitHub\\misinfo_detection\\content_analysis\\classifier_comparison\\models\\hyperlinking')\n",
    "train_hyperlinking_models(100, df, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:16:23<00:00, 45.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train and save 100 content models\n",
    "def train_content_models(num_models, df, out_dir):\n",
    "    '''\n",
    "    To create X, y\n",
    "    y = df['y'].to_numpy()\n",
    "    X, _, _ = tf_idf_transformation(df, 'tokenized')\n",
    "    '''\n",
    "    for i in tqdm(range(num_models)):\n",
    "        model, _, _, _, _, _, _ = train_logistic_regression(df, 'tokenized')\n",
    "        outfile = out_dir / (str(i)+'.pkl')\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        f.close()\n",
    "    return\n",
    "\n",
    "out_dir = Path(r'C:\\Users\\ewais\\Documents\\GitHub\\misinfo_detection\\content_analysis\\classifier_comparison\\models\\content')\n",
    "train_content_models(100, df, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:54<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train and save 100 meta models\n",
    "def train_meta_models(num_models, df, out_dir):\n",
    "    '''\n",
    "    To create X, y\n",
    "    y = df['y'].to_numpy()\n",
    "    X, _, _ = tf_idf_transformation(df, 'meta tokenized')\n",
    "    '''\n",
    "    for i in tqdm(range(num_models)):\n",
    "        model, _, _, _, _, _, _ = train_logistic_regression(df, 'meta tokenized')\n",
    "        outfile = out_dir / (str(i)+'.pkl')\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        f.close()\n",
    "    return\n",
    "\n",
    "out_dir = Path(r'C:\\Users\\ewais\\Documents\\GitHub\\misinfo_detection\\content_analysis\\classifier_comparison\\models\\meta')\n",
    "train_meta_models(100, df, out_dir)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
