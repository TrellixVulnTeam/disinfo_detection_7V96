{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"full dataframe\" refers to a dataframe with all domains and all features, such that classifiers may be trained simply by passing the dataframe to a function and selecting the proper columns\n",
    "\n",
    "We are interested in three sets of features:\n",
    "- Hyperlinking\n",
    "- Content analysis\n",
    "- Meta tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Start by loading the content dataframe\n",
    "# It is saved as html_df_tokenized.pkl\n",
    "with open(r'C:\\Users\\ewais\\Documents\\GitHub\\misinfo_detection\\content_analysis\\analyses v2\\html_df_tokenized.pkl', 'rb') as f:\n",
    "    content_df = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# Then, load the meta tag dataframe\n",
    "# It is saved as df_tokenized.pkl\n",
    "with open(r'C:\\Users\\ewais\\Documents\\GitHub\\misinfo_detection\\meta tag analysis\\df_tokenized.pkl', 'rb') as f:\n",
    "    meta_df = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# Load the hyperlinking dataframe\n",
    "# It is saved as domain_df.pkl\n",
    "with open(r'C:\\Users\\ewais\\Documents\\GitHub\\misinfo_detection\\mutual_hyperlinking\\hyperlinking_df.pkl', 'rb') as f:\n",
    "    hyperlinking_df = pickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## meta_df is built off of content_df, so we will only use meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~ Content ~~~~~~~~\n",
      "Index(['index', 'site', 'label', 'y', 'text', 'tokenized'], dtype='object')\n",
      "~~~~~~~ Meta Tags ~~~~~~~~\n",
      "Index(['index', 'site', 'label', 'y', 'text', 'tokenized', 'meta text',\n",
      "       'meta tokenized'],\n",
      "      dtype='object')\n",
      "~~~~~~~ Hyperlinking ~~~~~~~~\n",
      "Index(['global_index', 'subindex', 'domain', 'label', 'num_incoming_sites',\n",
      "       'incoming_sites_list', 'num_incoming_real_sites',\n",
      "       'incoming_real_sites_list', 'num_incoming_fake_sites',\n",
      "       'incoming_fake_sites_list', 'num_outgoing_fake_sites',\n",
      "       'num_outgoing_real_sites', 'num_outgoing_sites',\n",
      "       'outgoing_fake_sites_list', 'outgoing_real_sites_list',\n",
      "       'outgoing_sites_list', 'percent_fake_incoming', 'percent_fake_outgoing',\n",
      "       'incoming_to_outgoing_ratio', 'color', 'vectorized_links', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get a sense of the columns of each dataframe\n",
    "def print_column_names(df_name, df):\n",
    "    print('~~~~~~~ {} ~~~~~~~~'.format(df_name))\n",
    "    print(df.columns)\n",
    "\n",
    "print_column_names('Content', content_df)\n",
    "print_column_names('Meta Tags', meta_df)\n",
    "print_column_names('Hyperlinking', hyperlinking_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rework the dataframes so they have the same column names\n",
    "meta_df = meta_df.reset_index().rename(columns = {'index' : 'subindex', 'level_0' : 'global_index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_index</th>\n",
       "      <th>subindex</th>\n",
       "      <th>site</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>meta text</th>\n",
       "      <th>meta tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>495</td>\n",
       "      <td>http://japaninsides.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>Over the generations, the most improved sector...</td>\n",
       "      <td>[gener, improv, sector, thi, fifteenth, versio...</td>\n",
       "      <td>Learn more about JapanJapan InsideLearn more ...</td>\n",
       "      <td>[learn, japanjapan, insidelearn, japan, learn,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>496</td>\n",
       "      <td>http://voxpoliticalonline.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>The constituencies that the Conservatives won ...</td>\n",
       "      <td>[constitu, conserv, north, england, contain, m...</td>\n",
       "      <td>Vox Political, Mike Sivier, politics, UK, Eng...</td>\n",
       "      <td>[vox, polit, mike, sivier, polit, uk, england,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>497</td>\n",
       "      <td>http://magavoter.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>Cookies are uniquely assigned to you, and can ...</td>\n",
       "      <td>[cooki, uniqu, assign, onli, read, web, server...</td>\n",
       "      <td>See relevant content for Magavoter.com</td>\n",
       "      <td>[see, relev, content, magavot, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>498</td>\n",
       "      <td>http://anthonyblogan.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>Current events related to politics, general ne...</td>\n",
       "      <td>[current, event, relat, polit, gener, news, in...</td>\n",
       "      <td>ANTHONYBLOGAN.com is an original news and opi...</td>\n",
       "      <td>[anthonyblogan, com, origin, news, opinion, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>499</td>\n",
       "      <td>http://focusonthefamily.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>1</td>\n",
       "      <td>Take a pregnancy for example. When the upstair...</td>\n",
       "      <td>[take, pregnanc, exampl, upstair, brain, ha, d...</td>\n",
       "      <td>books, audio, parenting books, marriage books...</td>\n",
       "      <td>[book, audio, parent, book, marriag, book, eva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     global_index  subindex                           site label  y  \\\n",
       "994           994       495        http://japaninsides.com  fake  1   \n",
       "995           995       496  http://voxpoliticalonline.com  fake  1   \n",
       "996           996       497           http://magavoter.com  fake  1   \n",
       "997           997       498       http://anthonyblogan.com  fake  1   \n",
       "998           998       499    http://focusonthefamily.com  fake  1   \n",
       "\n",
       "                                                  text  \\\n",
       "994  Over the generations, the most improved sector...   \n",
       "995  The constituencies that the Conservatives won ...   \n",
       "996  Cookies are uniquely assigned to you, and can ...   \n",
       "997  Current events related to politics, general ne...   \n",
       "998  Take a pregnancy for example. When the upstair...   \n",
       "\n",
       "                                             tokenized  \\\n",
       "994  [gener, improv, sector, thi, fifteenth, versio...   \n",
       "995  [constitu, conserv, north, england, contain, m...   \n",
       "996  [cooki, uniqu, assign, onli, read, web, server...   \n",
       "997  [current, event, relat, polit, gener, news, in...   \n",
       "998  [take, pregnanc, exampl, upstair, brain, ha, d...   \n",
       "\n",
       "                                             meta text  \\\n",
       "994   Learn more about JapanJapan InsideLearn more ...   \n",
       "995   Vox Political, Mike Sivier, politics, UK, Eng...   \n",
       "996             See relevant content for Magavoter.com   \n",
       "997   ANTHONYBLOGAN.com is an original news and opi...   \n",
       "998   books, audio, parenting books, marriage books...   \n",
       "\n",
       "                                        meta tokenized  \n",
       "994  [learn, japanjapan, insidelearn, japan, learn,...  \n",
       "995  [vox, polit, mike, sivier, polit, uk, england,...  \n",
       "996                [see, relev, content, magavot, com]  \n",
       "997  [anthonyblogan, com, origin, news, opinion, we...  \n",
       "998  [book, audio, parent, book, marriag, book, eva...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~ Full ~~~~~~~~\n",
      "Index(['global_index', 'subindex', 'site', 'label', 'y', 'text', 'tokenized',\n",
      "       'meta text', 'meta tokenized', 'domain', 'num_incoming_sites',\n",
      "       'incoming_sites_list', 'num_incoming_real_sites',\n",
      "       'incoming_real_sites_list', 'num_incoming_fake_sites',\n",
      "       'incoming_fake_sites_list', 'num_outgoing_fake_sites',\n",
      "       'num_outgoing_real_sites', 'num_outgoing_sites',\n",
      "       'outgoing_fake_sites_list', 'outgoing_real_sites_list',\n",
      "       'outgoing_sites_list', 'percent_fake_incoming', 'percent_fake_outgoing',\n",
      "       'incoming_to_outgoing_ratio', 'color', 'vectorized_links'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Join the dataframes on global_index\n",
    "full_df = meta_df.join(hyperlinking_df, lsuffix='_meta', rsuffix='_hyperlinking', on='global_index')\n",
    "\n",
    "# Remove redundant columns\n",
    "full_df = full_df.drop(columns=['global_index_hyperlinking', 'subindex_hyperlinking', 'label_hyperlinking', 'y_hyperlinking'])\n",
    "full_df = full_df.rename(columns={'global_index_meta' : 'global_index', 'subindex_meta' : 'subindex', 'label_meta': 'label', 'y_meta': 'y'})\n",
    "print_column_names('Full', full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "with open('full_df.pkl', 'wb') as f:\n",
    "    pickle.dump(full_df, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
