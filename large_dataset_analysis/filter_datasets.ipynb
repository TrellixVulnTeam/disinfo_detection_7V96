{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The purpose of this notebook is to ensure there are no repeated domains within the fake dataset as well as ensuring there are no fake site present in the alexa top 10,0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# First, load the datasets\n",
    "real_df = pd.read_csv(str(Path.cwd().parent / 'new data' / 'Large Dataset' / 'real.csv'), header=None)\n",
    "fake_df = pd.read_csv(str(Path.cwd().parent / 'new data' / 'Large Dataset' / 'fake.csv'), header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = real_df[0].tolist()\n",
    "fake = fake_df[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "\n",
    "def domainify(x):\n",
    "    if tldextract.extract(x).subdomain:\n",
    "        return tldextract.extract(x).subdomain + '.' + tldextract.extract(x).domain + '.' + tldextract.extract(x).suffix\n",
    "    else:\n",
    "        return tldextract.extract(x).domain + '.' + tldextract.extract(x).suffix\n",
    "# domainify = lambda x: tldextract.extract(x).subdomain + '.' + tldextract.extract(x).domain + '.' + tldextract.extract(x).suffix\n",
    "real_domains = [domainify(x) for x in real]\n",
    "fake_domains = [domainify(x) for x in fake]\n",
    "\n",
    "fake_domains = list(set(fake_domains))\n",
    "# Remove real domains that exist in the fake dataset\n",
    "real_domains= [x for x in real_domains if x not in fake_domains]\n",
    "\n",
    "httpify = lambda x: 'http://www.' + x\n",
    "real_domains = [httpify(x) for x in real_domains]\n",
    "fake_domains = [httpify(x) for x in fake_domains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Real Domains: 9955\n",
      "Number of Fake Domains: 3403\n",
      "Number of Fake Domains Filtered out of Real Dataset: 45\n"
     ]
    }
   ],
   "source": [
    "# Some statistics\n",
    "print(\"Number of Real Domains: {}\".format(len(real_domains)))\n",
    "print('Number of Fake Domains: {}'.format(len(fake_domains)))\n",
    "print('Number of Fake Domains Filtered out of Real Dataset: {}'.format(10000 - len(real_domains)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('large_fake_list.pkl', 'wb') as f:\n",
    "    pickle.dump(fake_domains, f)\n",
    "f.close()\n",
    "\n",
    "with open('large_real_list.pkl', 'wb') as f:\n",
    "    pickle.dump(real_domains, f)\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
