{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takes full_df (containing all features of the scraped data), creates classifiers and uses them to find the top logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_index</th>\n",
       "      <th>subindex</th>\n",
       "      <th>site</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>meta text</th>\n",
       "      <th>meta tokenized</th>\n",
       "      <th>domain</th>\n",
       "      <th>...</th>\n",
       "      <th>num_outgoing_real_sites</th>\n",
       "      <th>num_outgoing_sites</th>\n",
       "      <th>outgoing_fake_sites_list</th>\n",
       "      <th>outgoing_real_sites_list</th>\n",
       "      <th>outgoing_sites_list</th>\n",
       "      <th>percent_fake_incoming</th>\n",
       "      <th>percent_fake_outgoing</th>\n",
       "      <th>incoming_to_outgoing_ratio</th>\n",
       "      <th>color</th>\n",
       "      <th>vectorized_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://9to5mac.com</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>In a memo that was leaked to the Verge , Cook ...</td>\n",
       "      <td>[memo, wa, leak, verg, cook, say, appl, “, eve...</td>\n",
       "      <td>News and reviews for Apple products, apps, an...</td>\n",
       "      <td>[news, review, appl, product, app, rumor, prov...</td>\n",
       "      <td>.9to5mac.com</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.deadline.com, .theverge.com, .sfexaminer.com...</td>\n",
       "      <td>[.deadline.com, .theverge.com, .sfexaminer.com...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>blue</td>\n",
       "      <td>[0.8, 0.0, 0.5555555555555556]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>http://wfae.org</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>Charlotte Talks    Local News Roundup: Housing...</td>\n",
       "      <td>[charlott, talk, local, news, roundup, hous, f...</td>\n",
       "      <td>Charlotte Podcasts,Charlotte music,Charlotte ...</td>\n",
       "      <td>[charlott, podcast, charlott, music, charlott,...</td>\n",
       "      <td>.wfae.org</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.gao.gov, .npr.org, .nytimes.com, .seattletim...</td>\n",
       "      <td>[.gao.gov, .npr.org, .nytimes.com, .seattletim...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>blue</td>\n",
       "      <td>[0.25, 0.0, 0.6666666666666666]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>http://climatefeedback.org</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>The workshop will then move to more concrete e...</td>\n",
       "      <td>[workshop, move, concret, exampl, initi, tackl...</td>\n",
       "      <td>Scientific Reference to Reliable Information ...</td>\n",
       "      <td>[scientif, refer, reliabl, inform, climat, cha...</td>\n",
       "      <td>.climatefeedback.org</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.smithsonianmag.com, .politico.com, .accuweat...</td>\n",
       "      <td>[.smithsonianmag.com, .politico.com, .accuweat...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>blue</td>\n",
       "      <td>[0.0, 0.0, 0.125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>http://wdbj7.com</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>Power Life by Tony Horton            All Adult...</td>\n",
       "      <td>[power, life, toni, horton, adult, due, larg, ...</td>\n",
       "      <td>wdbj, virginia local news, virginia weather, ...</td>\n",
       "      <td>[wdbj, virginia, local, news, virginia, weathe...</td>\n",
       "      <td>.wdbj7.com</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.nasa.gov, .nbc12.com]</td>\n",
       "      <td>[.nasa.gov, .nbc12.com]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>blue</td>\n",
       "      <td>[0.25, 0.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>http://keyc.com</td>\n",
       "      <td>real</td>\n",
       "      <td>0</td>\n",
       "      <td>Good To Know This       Recommended by        ...</td>\n",
       "      <td>[good, know, thi, recommend, recommend, high, ...</td>\n",
       "      <td>keyc, keyc 12 keyc news 12, keyc tv, keyc new...</td>\n",
       "      <td>[keyc, keyc, keyc, news, keyc, tv, keyc, news,...</td>\n",
       "      <td>.keyc.com</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[.startribune.com, .wrtv.com]</td>\n",
       "      <td>[.startribune.com, .wrtv.com]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>blue</td>\n",
       "      <td>[1.0, 0.0, 0.5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_index  subindex                        site label  y  \\\n",
       "0             0         0          http://9to5mac.com  real  0   \n",
       "1             1         1             http://wfae.org  real  0   \n",
       "2             2         2  http://climatefeedback.org  real  0   \n",
       "3             3         3            http://wdbj7.com  real  0   \n",
       "4             4         4             http://keyc.com  real  0   \n",
       "\n",
       "                                                text  \\\n",
       "0  In a memo that was leaked to the Verge , Cook ...   \n",
       "1  Charlotte Talks    Local News Roundup: Housing...   \n",
       "2  The workshop will then move to more concrete e...   \n",
       "3  Power Life by Tony Horton            All Adult...   \n",
       "4  Good To Know This       Recommended by        ...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [memo, wa, leak, verg, cook, say, appl, “, eve...   \n",
       "1  [charlott, talk, local, news, roundup, hous, f...   \n",
       "2  [workshop, move, concret, exampl, initi, tackl...   \n",
       "3  [power, life, toni, horton, adult, due, larg, ...   \n",
       "4  [good, know, thi, recommend, recommend, high, ...   \n",
       "\n",
       "                                           meta text  \\\n",
       "0   News and reviews for Apple products, apps, an...   \n",
       "1   Charlotte Podcasts,Charlotte music,Charlotte ...   \n",
       "2   Scientific Reference to Reliable Information ...   \n",
       "3   wdbj, virginia local news, virginia weather, ...   \n",
       "4   keyc, keyc 12 keyc news 12, keyc tv, keyc new...   \n",
       "\n",
       "                                      meta tokenized                domain  \\\n",
       "0  [news, review, appl, product, app, rumor, prov...          .9to5mac.com   \n",
       "1  [charlott, podcast, charlott, music, charlott,...             .wfae.org   \n",
       "2  [scientif, refer, reliabl, inform, climat, cha...  .climatefeedback.org   \n",
       "3  [wdbj, virginia, local, news, virginia, weathe...            .wdbj7.com   \n",
       "4  [keyc, keyc, keyc, news, keyc, tv, keyc, news,...             .keyc.com   \n",
       "\n",
       "   ...  num_outgoing_real_sites num_outgoing_sites  outgoing_fake_sites_list  \\\n",
       "0  ...                        9                  9                        []   \n",
       "1  ...                        6                  6                        []   \n",
       "2  ...                        8                  8                        []   \n",
       "3  ...                        2                  2                        []   \n",
       "4  ...                        2                  2                        []   \n",
       "\n",
       "                            outgoing_real_sites_list  \\\n",
       "0  [.deadline.com, .theverge.com, .sfexaminer.com...   \n",
       "1  [.gao.gov, .npr.org, .nytimes.com, .seattletim...   \n",
       "2  [.smithsonianmag.com, .politico.com, .accuweat...   \n",
       "3                            [.nasa.gov, .nbc12.com]   \n",
       "4                      [.startribune.com, .wrtv.com]   \n",
       "\n",
       "                                 outgoing_sites_list percent_fake_incoming  \\\n",
       "0  [.deadline.com, .theverge.com, .sfexaminer.com...                  0.80   \n",
       "1  [.gao.gov, .npr.org, .nytimes.com, .seattletim...                  0.25   \n",
       "2  [.smithsonianmag.com, .politico.com, .accuweat...                  0.00   \n",
       "3                            [.nasa.gov, .nbc12.com]                  0.25   \n",
       "4                      [.startribune.com, .wrtv.com]                  1.00   \n",
       "\n",
       "   percent_fake_outgoing  incoming_to_outgoing_ratio  color  \\\n",
       "0                    0.0                    0.555556   blue   \n",
       "1                    0.0                    0.666667   blue   \n",
       "2                    0.0                    0.125000   blue   \n",
       "3                    0.0                    2.000000   blue   \n",
       "4                    0.0                    0.500000   blue   \n",
       "\n",
       "                  vectorized_links  \n",
       "0   [0.8, 0.0, 0.5555555555555556]  \n",
       "1  [0.25, 0.0, 0.6666666666666666]  \n",
       "2                [0.0, 0.0, 0.125]  \n",
       "3                 [0.25, 0.0, 2.0]  \n",
       "4                  [1.0, 0.0, 0.5]  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "# First, load the dataframe\n",
    "with open(Path.cwd().parent / 'content_analysis' / 'classifier_comparison' / 'full_df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode:\n",
    "\n",
    "For both meta tags and content:\n",
    "\n",
    "Use logit_explained_variance to get a list of top logit_tokens\n",
    "Use logit_tokens to generate a vocab_list\n",
    "Use the vocab_list along with vocabify_dataframe to generate a new set of reduced_tokens\n",
    "Featurize the tokens w/ TF-IDF, save this as another column\n",
    "\n",
    "Then:\n",
    "\n",
    "Combine all the featurized vectors together and train a logistic regression classifier on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [19:38<00:00, 47.13s/it]\n",
      "100%|██████████| 25/25 [01:17<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from analysis_functions import *\n",
    "\n",
    "_, _, content_logit_tokens = logit_explained_variance(df, 'tokenized', num_iterations=25)\n",
    "_, _, meta_logit_tokens = logit_explained_variance(df, 'meta tokenized', num_iterations=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content_logit_tokens.pkl', 'wb') as f:\n",
    "    pickle.dump(content_logit_tokens, f)\n",
    "f.close()\n",
    "with open('meta_logit_tokens.pkl', 'wb') as f:\n",
    "    pickle.dump(meta_logit_tokens, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wordpress', 'obituari', 'privaci', 'web', 'uncategor', 'republ', 'di', 'kamala', 'trump', 'prank', 'yakima', 'brainberri', 'liberti', 'biden', 'dr', 'vermont', 'click', 'mask', 'net', 'menu', 'newslett', 'subscrib', 'freedom', 'browser', 'funer', 'ddo', 'art', 'plandem', 'der', 'harri']\n",
      "['archiv', 'none', 'china', 'biden', 'trump', 'weather', 'counti', 'sport', 'liberti', 'scienc', 'area', 'citi', 'di', 'page', 'dr', 'site', 'hi', 'team', 'parent', 'healthi', 'evid', 'polic', 'climat', 'plandem', 'freedom', 'signal', 'florida', 'medium', 'tea', 'greek']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "with open(Path.cwd().parent / 'content_analysis' / 'classifier_comparison' / 'full_df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "f.close()\n",
    "with open('content_logit_tokens.pkl', 'rb') as f:\n",
    "    content_logit_tokens = pickle.load(f)\n",
    "f.close()\n",
    "with open('meta_logit_tokens.pkl', 'rb') as f:\n",
    "    meta_logit_tokens = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "def vocab_list_from_logit_tokens(logit_tokens, num_tokens=30):\n",
    "    '''\n",
    "    Takes logit_tokens output by logit_explained_variance() and creates vocab_list for vocabify_dataframe\n",
    "    '''\n",
    "    vocab_list = []\n",
    "    for i in range(1,num_tokens+1):\n",
    "        vocab_list.append(logit_tokens[i])\n",
    "    return vocab_list\n",
    "\n",
    "content_vocab_list = vocab_list_from_logit_tokens(content_logit_tokens)\n",
    "meta_vocab_list = vocab_list_from_logit_tokens(meta_logit_tokens)\n",
    "\n",
    "print(content_vocab_list)\n",
    "print(meta_vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_functions import *\n",
    "\n",
    "df = vocabify_dataframe(df, 'tokenized', 'reduced_content', content_vocab_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vocabify_dataframe(df, 'meta tokenized', 'reduced_meta', meta_vocab_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "with open('full_df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TF-IDF representations of the proper columns\n",
    "\n",
    "meta_tfidf, meta_vocab, _ = tfidf_transformation(df, 'reduced_meta')\n",
    "content_tfidf, content_vocab, _ = tfidf_transformation(df, 'reduced_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tfidf_vectors_to_dataframe(df, tfidf, new_col_name):\n",
    "    assert len(df) == tfidf.shape[0], 'ERROR: size mismatch'\n",
    "    \n",
    "    # Convert to array\n",
    "    tfidf = tfidf.toarray()\n",
    "    # Normalize\n",
    "    tfidf = tfidf / np.max(tfidf)\n",
    "\n",
    "    new_col = []\n",
    "    for i in range(tfidf.shape[0]):\n",
    "        new_col.append(tfidf[i,:])\n",
    "\n",
    "    df[new_col_name] = new_col\n",
    "    return df\n",
    "\n",
    "df = add_tfidf_vectors_to_dataframe(df, meta_tfidf, 'meta_tfidf')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_tfidf_vectors_to_dataframe(df, content_tfidf, 'content_tfidf')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, combine the vectors into a single feature, the order will be [content, meta, hyperlinking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(df):\n",
    "    df['combined_features'] = df.apply(lambda row: np.concatenate((row.content_tfidf, row.meta_tfidf, row.vectorized_links), axis=0),axis=1)\n",
    "    return df\n",
    "\n",
    "df = combine_features(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df\n",
    "with open('full_df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1131efc7635b497546d7e8fbc76ad9d1f9d5d5d7857bcde935d6feea39d08984"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
